/**
 * Autogenerated by Thrift Compiler (0.7.0)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.nearinfinity.blur.thrift.generated;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.nio.ByteBuffer;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class TableDescriptor implements org.apache.thrift.TBase<TableDescriptor, TableDescriptor._Fields>, java.io.Serializable, Cloneable {
  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("TableDescriptor");

  private static final org.apache.thrift.protocol.TField IS_ENABLED_FIELD_DESC = new org.apache.thrift.protocol.TField("isEnabled", org.apache.thrift.protocol.TType.BOOL, (short)1);
  private static final org.apache.thrift.protocol.TField ANALYZER_DEFINITION_FIELD_DESC = new org.apache.thrift.protocol.TField("analyzerDefinition", org.apache.thrift.protocol.TType.STRUCT, (short)2);
  private static final org.apache.thrift.protocol.TField SHARD_COUNT_FIELD_DESC = new org.apache.thrift.protocol.TField("shardCount", org.apache.thrift.protocol.TType.I32, (short)3);
  private static final org.apache.thrift.protocol.TField TABLE_URI_FIELD_DESC = new org.apache.thrift.protocol.TField("tableUri", org.apache.thrift.protocol.TType.STRING, (short)4);
  private static final org.apache.thrift.protocol.TField COMPRESSION_CLASS_FIELD_DESC = new org.apache.thrift.protocol.TField("compressionClass", org.apache.thrift.protocol.TType.STRING, (short)5);
  private static final org.apache.thrift.protocol.TField COMPRESSION_BLOCK_SIZE_FIELD_DESC = new org.apache.thrift.protocol.TField("compressionBlockSize", org.apache.thrift.protocol.TType.I32, (short)6);
  private static final org.apache.thrift.protocol.TField CLUSTER_FIELD_DESC = new org.apache.thrift.protocol.TField("cluster", org.apache.thrift.protocol.TType.STRING, (short)7);

  public boolean isEnabled; // required
  public AnalyzerDefinition analyzerDefinition; // required
  public int shardCount; // required
  public String tableUri; // required
  public String compressionClass; // required
  public int compressionBlockSize; // required
  public String cluster; // required

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
    IS_ENABLED((short)1, "isEnabled"),
    ANALYZER_DEFINITION((short)2, "analyzerDefinition"),
    SHARD_COUNT((short)3, "shardCount"),
    TABLE_URI((short)4, "tableUri"),
    COMPRESSION_CLASS((short)5, "compressionClass"),
    COMPRESSION_BLOCK_SIZE((short)6, "compressionBlockSize"),
    CLUSTER((short)7, "cluster");

    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      switch(fieldId) {
        case 1: // IS_ENABLED
          return IS_ENABLED;
        case 2: // ANALYZER_DEFINITION
          return ANALYZER_DEFINITION;
        case 3: // SHARD_COUNT
          return SHARD_COUNT;
        case 4: // TABLE_URI
          return TABLE_URI;
        case 5: // COMPRESSION_CLASS
          return COMPRESSION_CLASS;
        case 6: // COMPRESSION_BLOCK_SIZE
          return COMPRESSION_BLOCK_SIZE;
        case 7: // CLUSTER
          return CLUSTER;
        default:
          return null;
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final int __ISENABLED_ISSET_ID = 0;
  private static final int __SHARDCOUNT_ISSET_ID = 1;
  private static final int __COMPRESSIONBLOCKSIZE_ISSET_ID = 2;
  private BitSet __isset_bit_vector = new BitSet(3);

  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
  static {
    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
    tmpMap.put(_Fields.IS_ENABLED, new org.apache.thrift.meta_data.FieldMetaData("isEnabled", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
    tmpMap.put(_Fields.ANALYZER_DEFINITION, new org.apache.thrift.meta_data.FieldMetaData("analyzerDefinition", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, AnalyzerDefinition.class)));
    tmpMap.put(_Fields.SHARD_COUNT, new org.apache.thrift.meta_data.FieldMetaData("shardCount", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
    tmpMap.put(_Fields.TABLE_URI, new org.apache.thrift.meta_data.FieldMetaData("tableUri", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    tmpMap.put(_Fields.COMPRESSION_CLASS, new org.apache.thrift.meta_data.FieldMetaData("compressionClass", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    tmpMap.put(_Fields.COMPRESSION_BLOCK_SIZE, new org.apache.thrift.meta_data.FieldMetaData("compressionBlockSize", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
    tmpMap.put(_Fields.CLUSTER, new org.apache.thrift.meta_data.FieldMetaData("cluster", org.apache.thrift.TFieldRequirementType.DEFAULT, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    metaDataMap = Collections.unmodifiableMap(tmpMap);
    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(TableDescriptor.class, metaDataMap);
  }

  public TableDescriptor() {
    this.isEnabled = true;

    this.shardCount = 1;

    this.compressionClass = "org.apache.hadoop.io.compress.DefaultCodec";

    this.compressionBlockSize = 32768;

  }

  public TableDescriptor(
    boolean isEnabled,
    AnalyzerDefinition analyzerDefinition,
    int shardCount,
    String tableUri,
    String compressionClass,
    int compressionBlockSize,
    String cluster)
  {
    this();
    this.isEnabled = isEnabled;
    setIsEnabledIsSet(true);
    this.analyzerDefinition = analyzerDefinition;
    this.shardCount = shardCount;
    setShardCountIsSet(true);
    this.tableUri = tableUri;
    this.compressionClass = compressionClass;
    this.compressionBlockSize = compressionBlockSize;
    setCompressionBlockSizeIsSet(true);
    this.cluster = cluster;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public TableDescriptor(TableDescriptor other) {
    __isset_bit_vector.clear();
    __isset_bit_vector.or(other.__isset_bit_vector);
    this.isEnabled = other.isEnabled;
    if (other.isSetAnalyzerDefinition()) {
      this.analyzerDefinition = new AnalyzerDefinition(other.analyzerDefinition);
    }
    this.shardCount = other.shardCount;
    if (other.isSetTableUri()) {
      this.tableUri = other.tableUri;
    }
    if (other.isSetCompressionClass()) {
      this.compressionClass = other.compressionClass;
    }
    this.compressionBlockSize = other.compressionBlockSize;
    if (other.isSetCluster()) {
      this.cluster = other.cluster;
    }
  }

  public TableDescriptor deepCopy() {
    return new TableDescriptor(this);
  }

  @Override
  public void clear() {
    this.isEnabled = true;

    this.analyzerDefinition = null;
    this.shardCount = 1;

    this.tableUri = null;
    this.compressionClass = "org.apache.hadoop.io.compress.DefaultCodec";

    this.compressionBlockSize = 32768;

    this.cluster = null;
  }

  public boolean isIsEnabled() {
    return this.isEnabled;
  }

  public TableDescriptor setIsEnabled(boolean isEnabled) {
    this.isEnabled = isEnabled;
    setIsEnabledIsSet(true);
    return this;
  }

  public void unsetIsEnabled() {
    __isset_bit_vector.clear(__ISENABLED_ISSET_ID);
  }

  /** Returns true if field isEnabled is set (has been assigned a value) and false otherwise */
  public boolean isSetIsEnabled() {
    return __isset_bit_vector.get(__ISENABLED_ISSET_ID);
  }

  public void setIsEnabledIsSet(boolean value) {
    __isset_bit_vector.set(__ISENABLED_ISSET_ID, value);
  }

  public AnalyzerDefinition getAnalyzerDefinition() {
    return this.analyzerDefinition;
  }

  public TableDescriptor setAnalyzerDefinition(AnalyzerDefinition analyzerDefinition) {
    this.analyzerDefinition = analyzerDefinition;
    return this;
  }

  public void unsetAnalyzerDefinition() {
    this.analyzerDefinition = null;
  }

  /** Returns true if field analyzerDefinition is set (has been assigned a value) and false otherwise */
  public boolean isSetAnalyzerDefinition() {
    return this.analyzerDefinition != null;
  }

  public void setAnalyzerDefinitionIsSet(boolean value) {
    if (!value) {
      this.analyzerDefinition = null;
    }
  }

  public int getShardCount() {
    return this.shardCount;
  }

  public TableDescriptor setShardCount(int shardCount) {
    this.shardCount = shardCount;
    setShardCountIsSet(true);
    return this;
  }

  public void unsetShardCount() {
    __isset_bit_vector.clear(__SHARDCOUNT_ISSET_ID);
  }

  /** Returns true if field shardCount is set (has been assigned a value) and false otherwise */
  public boolean isSetShardCount() {
    return __isset_bit_vector.get(__SHARDCOUNT_ISSET_ID);
  }

  public void setShardCountIsSet(boolean value) {
    __isset_bit_vector.set(__SHARDCOUNT_ISSET_ID, value);
  }

  public String getTableUri() {
    return this.tableUri;
  }

  public TableDescriptor setTableUri(String tableUri) {
    this.tableUri = tableUri;
    return this;
  }

  public void unsetTableUri() {
    this.tableUri = null;
  }

  /** Returns true if field tableUri is set (has been assigned a value) and false otherwise */
  public boolean isSetTableUri() {
    return this.tableUri != null;
  }

  public void setTableUriIsSet(boolean value) {
    if (!value) {
      this.tableUri = null;
    }
  }

  public String getCompressionClass() {
    return this.compressionClass;
  }

  public TableDescriptor setCompressionClass(String compressionClass) {
    this.compressionClass = compressionClass;
    return this;
  }

  public void unsetCompressionClass() {
    this.compressionClass = null;
  }

  /** Returns true if field compressionClass is set (has been assigned a value) and false otherwise */
  public boolean isSetCompressionClass() {
    return this.compressionClass != null;
  }

  public void setCompressionClassIsSet(boolean value) {
    if (!value) {
      this.compressionClass = null;
    }
  }

  public int getCompressionBlockSize() {
    return this.compressionBlockSize;
  }

  public TableDescriptor setCompressionBlockSize(int compressionBlockSize) {
    this.compressionBlockSize = compressionBlockSize;
    setCompressionBlockSizeIsSet(true);
    return this;
  }

  public void unsetCompressionBlockSize() {
    __isset_bit_vector.clear(__COMPRESSIONBLOCKSIZE_ISSET_ID);
  }

  /** Returns true if field compressionBlockSize is set (has been assigned a value) and false otherwise */
  public boolean isSetCompressionBlockSize() {
    return __isset_bit_vector.get(__COMPRESSIONBLOCKSIZE_ISSET_ID);
  }

  public void setCompressionBlockSizeIsSet(boolean value) {
    __isset_bit_vector.set(__COMPRESSIONBLOCKSIZE_ISSET_ID, value);
  }

  public String getCluster() {
    return this.cluster;
  }

  public TableDescriptor setCluster(String cluster) {
    this.cluster = cluster;
    return this;
  }

  public void unsetCluster() {
    this.cluster = null;
  }

  /** Returns true if field cluster is set (has been assigned a value) and false otherwise */
  public boolean isSetCluster() {
    return this.cluster != null;
  }

  public void setClusterIsSet(boolean value) {
    if (!value) {
      this.cluster = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case IS_ENABLED:
      if (value == null) {
        unsetIsEnabled();
      } else {
        setIsEnabled((Boolean)value);
      }
      break;

    case ANALYZER_DEFINITION:
      if (value == null) {
        unsetAnalyzerDefinition();
      } else {
        setAnalyzerDefinition((AnalyzerDefinition)value);
      }
      break;

    case SHARD_COUNT:
      if (value == null) {
        unsetShardCount();
      } else {
        setShardCount((Integer)value);
      }
      break;

    case TABLE_URI:
      if (value == null) {
        unsetTableUri();
      } else {
        setTableUri((String)value);
      }
      break;

    case COMPRESSION_CLASS:
      if (value == null) {
        unsetCompressionClass();
      } else {
        setCompressionClass((String)value);
      }
      break;

    case COMPRESSION_BLOCK_SIZE:
      if (value == null) {
        unsetCompressionBlockSize();
      } else {
        setCompressionBlockSize((Integer)value);
      }
      break;

    case CLUSTER:
      if (value == null) {
        unsetCluster();
      } else {
        setCluster((String)value);
      }
      break;

    }
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case IS_ENABLED:
      return Boolean.valueOf(isIsEnabled());

    case ANALYZER_DEFINITION:
      return getAnalyzerDefinition();

    case SHARD_COUNT:
      return Integer.valueOf(getShardCount());

    case TABLE_URI:
      return getTableUri();

    case COMPRESSION_CLASS:
      return getCompressionClass();

    case COMPRESSION_BLOCK_SIZE:
      return Integer.valueOf(getCompressionBlockSize());

    case CLUSTER:
      return getCluster();

    }
    throw new IllegalStateException();
  }

  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case IS_ENABLED:
      return isSetIsEnabled();
    case ANALYZER_DEFINITION:
      return isSetAnalyzerDefinition();
    case SHARD_COUNT:
      return isSetShardCount();
    case TABLE_URI:
      return isSetTableUri();
    case COMPRESSION_CLASS:
      return isSetCompressionClass();
    case COMPRESSION_BLOCK_SIZE:
      return isSetCompressionBlockSize();
    case CLUSTER:
      return isSetCluster();
    }
    throw new IllegalStateException();
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof TableDescriptor)
      return this.equals((TableDescriptor)that);
    return false;
  }

  public boolean equals(TableDescriptor that) {
    if (that == null)
      return false;

    boolean this_present_isEnabled = true;
    boolean that_present_isEnabled = true;
    if (this_present_isEnabled || that_present_isEnabled) {
      if (!(this_present_isEnabled && that_present_isEnabled))
        return false;
      if (this.isEnabled != that.isEnabled)
        return false;
    }

    boolean this_present_analyzerDefinition = true && this.isSetAnalyzerDefinition();
    boolean that_present_analyzerDefinition = true && that.isSetAnalyzerDefinition();
    if (this_present_analyzerDefinition || that_present_analyzerDefinition) {
      if (!(this_present_analyzerDefinition && that_present_analyzerDefinition))
        return false;
      if (!this.analyzerDefinition.equals(that.analyzerDefinition))
        return false;
    }

    boolean this_present_shardCount = true;
    boolean that_present_shardCount = true;
    if (this_present_shardCount || that_present_shardCount) {
      if (!(this_present_shardCount && that_present_shardCount))
        return false;
      if (this.shardCount != that.shardCount)
        return false;
    }

    boolean this_present_tableUri = true && this.isSetTableUri();
    boolean that_present_tableUri = true && that.isSetTableUri();
    if (this_present_tableUri || that_present_tableUri) {
      if (!(this_present_tableUri && that_present_tableUri))
        return false;
      if (!this.tableUri.equals(that.tableUri))
        return false;
    }

    boolean this_present_compressionClass = true && this.isSetCompressionClass();
    boolean that_present_compressionClass = true && that.isSetCompressionClass();
    if (this_present_compressionClass || that_present_compressionClass) {
      if (!(this_present_compressionClass && that_present_compressionClass))
        return false;
      if (!this.compressionClass.equals(that.compressionClass))
        return false;
    }

    boolean this_present_compressionBlockSize = true;
    boolean that_present_compressionBlockSize = true;
    if (this_present_compressionBlockSize || that_present_compressionBlockSize) {
      if (!(this_present_compressionBlockSize && that_present_compressionBlockSize))
        return false;
      if (this.compressionBlockSize != that.compressionBlockSize)
        return false;
    }

    boolean this_present_cluster = true && this.isSetCluster();
    boolean that_present_cluster = true && that.isSetCluster();
    if (this_present_cluster || that_present_cluster) {
      if (!(this_present_cluster && that_present_cluster))
        return false;
      if (!this.cluster.equals(that.cluster))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    return 0;
  }

  public int compareTo(TableDescriptor other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    TableDescriptor typedOther = (TableDescriptor)other;

    lastComparison = Boolean.valueOf(isSetIsEnabled()).compareTo(typedOther.isSetIsEnabled());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetIsEnabled()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.isEnabled, typedOther.isEnabled);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetAnalyzerDefinition()).compareTo(typedOther.isSetAnalyzerDefinition());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetAnalyzerDefinition()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.analyzerDefinition, typedOther.analyzerDefinition);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetShardCount()).compareTo(typedOther.isSetShardCount());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetShardCount()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.shardCount, typedOther.shardCount);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetTableUri()).compareTo(typedOther.isSetTableUri());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetTableUri()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.tableUri, typedOther.tableUri);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetCompressionClass()).compareTo(typedOther.isSetCompressionClass());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetCompressionClass()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.compressionClass, typedOther.compressionClass);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetCompressionBlockSize()).compareTo(typedOther.isSetCompressionBlockSize());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetCompressionBlockSize()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.compressionBlockSize, typedOther.compressionBlockSize);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetCluster()).compareTo(typedOther.isSetCluster());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetCluster()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.cluster, typedOther.cluster);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    return 0;
  }

  public _Fields fieldForId(int fieldId) {
    return _Fields.findByThriftId(fieldId);
  }

  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
    org.apache.thrift.protocol.TField field;
    iprot.readStructBegin();
    while (true)
    {
      field = iprot.readFieldBegin();
      if (field.type == org.apache.thrift.protocol.TType.STOP) { 
        break;
      }
      switch (field.id) {
        case 1: // IS_ENABLED
          if (field.type == org.apache.thrift.protocol.TType.BOOL) {
            this.isEnabled = iprot.readBool();
            setIsEnabledIsSet(true);
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 2: // ANALYZER_DEFINITION
          if (field.type == org.apache.thrift.protocol.TType.STRUCT) {
            this.analyzerDefinition = new AnalyzerDefinition();
            this.analyzerDefinition.read(iprot);
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 3: // SHARD_COUNT
          if (field.type == org.apache.thrift.protocol.TType.I32) {
            this.shardCount = iprot.readI32();
            setShardCountIsSet(true);
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 4: // TABLE_URI
          if (field.type == org.apache.thrift.protocol.TType.STRING) {
            this.tableUri = iprot.readString();
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 5: // COMPRESSION_CLASS
          if (field.type == org.apache.thrift.protocol.TType.STRING) {
            this.compressionClass = iprot.readString();
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 6: // COMPRESSION_BLOCK_SIZE
          if (field.type == org.apache.thrift.protocol.TType.I32) {
            this.compressionBlockSize = iprot.readI32();
            setCompressionBlockSizeIsSet(true);
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        case 7: // CLUSTER
          if (field.type == org.apache.thrift.protocol.TType.STRING) {
            this.cluster = iprot.readString();
          } else { 
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
          }
          break;
        default:
          org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
      }
      iprot.readFieldEnd();
    }
    iprot.readStructEnd();

    // check for required fields of primitive type, which can't be checked in the validate method
    validate();
  }

  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
    validate();

    oprot.writeStructBegin(STRUCT_DESC);
    oprot.writeFieldBegin(IS_ENABLED_FIELD_DESC);
    oprot.writeBool(this.isEnabled);
    oprot.writeFieldEnd();
    if (this.analyzerDefinition != null) {
      oprot.writeFieldBegin(ANALYZER_DEFINITION_FIELD_DESC);
      this.analyzerDefinition.write(oprot);
      oprot.writeFieldEnd();
    }
    oprot.writeFieldBegin(SHARD_COUNT_FIELD_DESC);
    oprot.writeI32(this.shardCount);
    oprot.writeFieldEnd();
    if (this.tableUri != null) {
      oprot.writeFieldBegin(TABLE_URI_FIELD_DESC);
      oprot.writeString(this.tableUri);
      oprot.writeFieldEnd();
    }
    if (this.compressionClass != null) {
      oprot.writeFieldBegin(COMPRESSION_CLASS_FIELD_DESC);
      oprot.writeString(this.compressionClass);
      oprot.writeFieldEnd();
    }
    oprot.writeFieldBegin(COMPRESSION_BLOCK_SIZE_FIELD_DESC);
    oprot.writeI32(this.compressionBlockSize);
    oprot.writeFieldEnd();
    if (this.cluster != null) {
      oprot.writeFieldBegin(CLUSTER_FIELD_DESC);
      oprot.writeString(this.cluster);
      oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("TableDescriptor(");
    boolean first = true;

    sb.append("isEnabled:");
    sb.append(this.isEnabled);
    first = false;
    if (!first) sb.append(", ");
    sb.append("analyzerDefinition:");
    if (this.analyzerDefinition == null) {
      sb.append("null");
    } else {
      sb.append(this.analyzerDefinition);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("shardCount:");
    sb.append(this.shardCount);
    first = false;
    if (!first) sb.append(", ");
    sb.append("tableUri:");
    if (this.tableUri == null) {
      sb.append("null");
    } else {
      sb.append(this.tableUri);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("compressionClass:");
    if (this.compressionClass == null) {
      sb.append("null");
    } else {
      sb.append(this.compressionClass);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("compressionBlockSize:");
    sb.append(this.compressionBlockSize);
    first = false;
    if (!first) sb.append(", ");
    sb.append("cluster:");
    if (this.cluster == null) {
      sb.append("null");
    } else {
      sb.append(this.cluster);
    }
    first = false;
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws org.apache.thrift.TException {
    // check for required fields
  }

  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
    try {
      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
    try {
      // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
      __isset_bit_vector = new BitSet(1);
      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

}

